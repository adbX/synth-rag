# Qdrant Component Summaries

| File | Method/Stack | Core Idea | Best Use Cases |
| --- | --- | --- | --- |
| `agentic-rag-crewai-zoom.md` | CrewAI agents orchestrated over Qdrant, SentenceTransformers (`all-MiniLM-L6-v2`) for embeddings, OpenAI `text-embedding-ada-002`, Anthropic Claude for reasoning, Streamlit UI | Demonstrates an agentic RAG loop where data loader batches meeting transcripts into Qdrant, CrewAI tools (search, calculator, analysis) plan multi-step work, and a chat UI streams progress | When you need multi-tool task decomposition (e.g., asking synthesizer manuals multi-hop questions) plus a lightweight dashboard to monitor long reasoning chains |
| `agentic-rag-langgraph.md` | LangGraph state machine coordinating OpenAI GPT-4o, OpenAI `text-embedding-3-small`, two Qdrant vector stores, BraveSearch API | Builds a graph-driven agent that dynamically routes queries to multiple retrievers or web search via tool-calling and conditional edges, enabling selective retrieval strategies | Complex troubleshooting over multiple manual collections (e.g., split by brand) where the agent must choose which library of PDFs or the web to trust per query |
| `hybrid-search-llamaindex-jinaai.md` | LlamaIndex + LlamaParse preprocessing, Jina Embeddings API (`jina-embeddings-v2-base-en`), Mixtral-8x7B via HuggingFace Inference, Qdrant Hybrid Cloud with `enable_hybrid=True` | End-to-end PDF chatbot: parse manuals to Markdown, build hybrid dense+sparse index inside Qdrant through LlamaIndex, and query via custom prompt with separate `sparse_top_k`/`similarity_top_k` knobs | Directly applicable to MIDI manuals where hybrid scoring (keyword + semantic) improves answers on spec-style PDFs parsed via LlamaParse |
| `pdf-retrieval-at-scale.md` | Vision LLMs ColPali / ColQwen2 generating multivectors, mean pooling compression, Qdrant multivector collections with prefetch + rerank | Proposes two-stage retrieval: first-stage HNSW built on mean-pooled vectors for speed, second-stage reranking on original multivectors to retain accuracy; includes batching, dataset guidance | Large manual libraries (full corpus) when you need scalable PDF page retrieval without OCR, especially if you lean on VLLMs for tables/figures |
| `Qdrant_and_LlamaIndex_â€”_A_new_way_to_keep_your_Q&A_systems_up_to_date.ipynb` | LlamaIndex `GPTVectorStoreIndex` over Qdrant client, OpenAI embeddings/LLM, Cohere Rerank, Recency postprocessor, HuggingFace news dataset | Notebook workflow that ingests docs into Qdrant, enables multiple query engines (baseline, recency, rerank, combined) and compares outputs to keep QA answers fresh and time-aware | Template for experimenting with freshness-aware ranking on manuals (e.g., prioritizing latest firmware sections) and testing rerankers before production |
| `reranking-hybrid-search.md` | FastEmbed dense (`all-MiniLM-L6-v2`), sparse (`Qdrant/bm25`), and ColBERT late-interaction embeddings; Qdrant multivector + sparse configs; prefetch-based hybrid search | Shows how to ingest/query multi-embedding data, run dense+sparse prefetch, then rerank with ColBERT multivectors in one `query_points` call to boost precision | When the manual corpus mixes keywords (model numbers) with semantics and needs ColBERT-style reranking without rebuilding the pipeline |
| `using-multivector-representations.md` | FastEmbed ColBERT integration, Qdrant multi-vector collections with selective HNSW, combined dense + multivector uploads | Guidance on when and how to store multivectors efficiently (disable HNSW for rerank heads, batch uploads, use `Prefetch` + `MaxSim`) and a minimal ColBERT demo | Optimizing storage/query costs if you add late-interaction rerankers to the MIDI chatbot (store dense vectors for recall, token-level vectors for accuracy only where needed) |


